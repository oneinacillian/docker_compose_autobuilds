
version: '3'
services:
  kibana:
    image: docker.elastic.co/kibana/kibana:8.17.0
    container_name: kibana
    environment:
      - "ELASTICSEARCH_URL=http://es1:9200"
      - "ELASTICSEARCH_HOSTS=http://es1:9200"
    ports:
      - "5601:5601"
    depends_on:
      - es1
    networks:
      - esnet
    deploy:
      resources:
        limits:
          memory: 2g
          cpus: "1"
    healthcheck:
      test: ["CMD-SHELL", "curl --silent --fail http://localhost:5601/api/status || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  redis:
    image: "redis:latest"
    container_name: redis
    ports:
      - "127.0.0.1:6379:6379"
    networks:
      - esnet
    volumes:
      - redisdata:/data
    deploy:
      resources:
        limits:
          memory: 2g
          cpus: "1"
    command: >
      redis-server 
      --appendonly yes 
      --appendfsync everysec
      --maxmemory 6gb
      --maxmemory-policy allkeys-lru
      --save 900 1
      --save 300 10
      --tcp-keepalive 60
      --io-threads 2
      --io-threads-do-reads yes
      --activedefrag yes
      --active-defrag-threshold-lower 10
      --active-defrag-threshold-upper 100
      --active-defrag-cycle-min 25
      --active-defrag-cycle-max 75
      --lazyfree-lazy-eviction yes
      --lazyfree-lazy-expire yes
      --lazyfree-lazy-server-del yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3

  rabbitmq:
    build:
      context: ./rabbitmq/Deployment
      dockerfile: Dockerfile.rabbitmq  
    container_name: rabbitmq
    environment:
      - RABBITMQ_DEFAULT_USER=rabbitmquser
      - RABBITMQ_DEFAULT_PASS=rabbitmqpass
      - RABBITMQ_DEFAULT_VHOST=hyperion
    command:
      - sh
      - -c
      - |
        rabbitmq-plugins disable --all &&
        rabbitmq-plugins enable rabbitmq_management rabbitmq_prometheus &&
        rabbitmq-server  
    ports:
      - "127.0.0.1:5672:5672"
      - "127.0.0.1:15672:15672"
      - "127.0.0.1:15692:15692"
    networks:
      - esnet
    deploy:
      resources:
        limits:
          memory: 2g
          cpus: "1"
    volumes:
      - rabbitmqdata:/var/lib/rabbitmq
      - ./rabbitmq/Deployment/rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf
      - ./rabbitmq/Deployment/rabbitmq-env.conf:/etc/rabbitmq/rabbitmq-env.conf   
    healthcheck:
      test: ["CMD", "rabbitmqctl", "status"]
      interval: 30s
      timeout: 10s
      retries: 5

  hyperion:
    container_name: hyperion
    tty: true
    build:
      context: ./hyperion/Deployment
      dockerfile: Dockerfile.hyperion
      args:
        - HYPERION_ENVIRONMENT=testnet
        - HYPERION_LAUNCH_ON_STARTUP=false
        - HYPERION_VERSION=3.5.0
        - RABBITMQ_DEFAULT_USER=rabbitmquser
        - RABBITMQ_DEFAULT_PASS=rabbitmqpass
    ports:
      - "7000:7000"
      - "1234:1234"
    networks:
      - esnet
    deploy:
      resources:
        limits:
          memory: 8g
          cpus: "2"
    volumes:
      - hyperiondata:/app/hyperiondata
    depends_on:
      - redis
      - rabbitmq
      - es1

  node:
    container_name: node
    tty: true
    build:
      context: ./hyperion/Deployment
      dockerfile: Dockerfile.node
      args:
        - HYPERION_ENVIRONMENT=testnet
        - HYPERION_LAUNCH_ON_STARTUP=false
        - LEAP_FILE=https://apt.eossweden.org/wax/pool/stable/w/wax-leap-503wax01/wax-leap-503wax01_5.0.3wax01-ubuntu-22.04_amd64.deb
        - LEAP_DEB_FILE=wax-leap-503wax01_5.0.3wax01-ubuntu-22.04_amd64.deb
    ports:
      - "127.0.0.1:9876:9876"
      - "127.0.0.1:8888:8888"
    networks:
      - esnet
    deploy:
      resources:
        limits:
          memory: 16g
          cpus: "4"
    volumes:
      - node:/app/node/data

  es1:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.17.0
    container_name: es1
    environment:
      - "node.name=es1"
      - "cluster.name=es-docker-cluster"
      - "cluster.initial_master_nodes=es1"
      - "discovery.seed_hosts=es1"
      - "network.host=0.0.0.0"
      - "network.publish_host=es1"
      - "transport.host=0.0.0.0"
      - "node.roles=[master, data, ingest, remote_cluster_client]"
      - "ES_JAVA_OPTS=-Xms15g -Xmx15g -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/var/log/elasticsearch"
      - "ES_HEAP_DUMP_PATH=/var/log/elasticsearch"
      - "ES_GC_LOG_PATH=/var/log/elasticsearch"
      - "bootstrap.memory_lock=true"
      - "xpack.security.enabled=false"
      - "xpack.monitoring.collection.enabled=true"
    ports:
      - "127.0.0.1:9200:9200"
      - "127.0.0.1:9300:9300"
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65535
        hard: 65535
    volumes:
      - esdata1:/usr/share/elasticsearch/data
      - ./elasticsearch/config/es1/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml
    networks:
      - esnet
    healthcheck:
      test: ["CMD-SHELL", "curl -s http://localhost:9200/_cluster/health | grep -vq \"status\":\"red\""]
      interval: 30s
      timeout: 30s
      retries: 5
      start_period: 60s

  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/hyperion/prometheus.yml:/etc/prometheus/prometheus.yml
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
    networks:
      - esnet
    deploy:
      resources:
        limits:
          memory: 2g
          cpus: "1"

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3030:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin123
    volumes:
      - ./grafana/provisioning/hyperion:/etc/grafana/provisioning
      - grafana-data:/var/lib/grafana
    networks:
      - esnet
    deploy:
      resources:
        limits:
          memory: 1g
          cpus: "1"

  nodeos-custom-exporter:
    build:
      context: ./custom-nodeos-exporter
      dockerfile: Dockerfile
    container_name: nodeos-custom-exporter
    ports:
      - "8000:8000"
    depends_on:
      - node
    networks:
      - esnet

  redis-exporter:
    image: oliver006/redis_exporter:latest
    container_name: redis-exporter
    environment:
      - REDIS_ADDR=redis:6379
    ports:
      - "9121:9121"
    networks:
      - esnet
    depends_on:
      - redis      

  elasticsearch-exporter-1:
    image: quay.io/prometheuscommunity/elasticsearch-exporter:latest
    container_name: elasticsearch-exporter-1
    command:
      - '--es.uri=http://es1:9200'
    ports:
      - "9114:9114"
    depends_on:
      - es1
    networks:
      - esnet

  haproxy:
    image: haproxy:2.8-alpine
    container_name: haproxy
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./haproxy/haproxy.cfg:/usr/local/etc/haproxy/haproxy.cfg:ro
      - ./haproxy/certs:/etc/haproxy/certs:ro
      - certbot-www:/var/www/certbot:ro
    depends_on:
      - hyperion
      - kibana
      - grafana
    networks:
      - esnet
    deploy:
      resources:
        limits:
          memory: 1g
          cpus: "1"
    healthcheck:
      test: ["CMD", "haproxy", "-c", "-f", "/usr/local/etc/haproxy/haproxy.cfg"]
      interval: 30s
      timeout: 10s
      retries: 3

volumes:
  grafana-data:
  redisdata:
  rabbitmqdata:
  hyperiondata:
  node:
  certbot-etc:
  certbot-var:
  certbot-www:
  esdata1:

networks:
  esnet:
